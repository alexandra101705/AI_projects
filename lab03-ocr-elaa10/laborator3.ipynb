{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "ðŸ’¡ Probleme\n",
    "Sa se identifice textul scris [de mana] intr-o imagine:\n",
    "\n",
    "- locatia textului\n",
    "- textul propriu-zis\n",
    "\n",
    "ðŸ“ Cerinte\n",
    "SpecificaÅ£i, implementaÅ£i È™i testaÈ›i subalgoritmi pentru problema enuntata. Sa se determine:\n",
    "\n",
    "- calitatea procesului de recunoastere a textului, atat la nivel de caracter, cat si la nivel de cuvant.\n",
    "            a. prin folosirea unei metrici de distanta sau\n",
    "            b. prin folosirea mai multor metrici de distanta.\n",
    "- calitatea localizarii corecte a textului in imagine\n",
    "- posibilitati de imbunatatire a recunoasterii textului"
   ],
   "id": "c426a74e5c835694"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T13:31:11.719142Z",
     "start_time": "2025-03-20T13:31:09.747677Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from enum import verify\n",
    "\n",
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
    "from azure.cognitiveservices.vision.computervision.models import VisualFeatureTypes\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "from array import array\n",
    "import os\n",
    "from PIL import Image\n",
    "import sys\n",
    "import time\n",
    "import Levenshtein\n",
    "from scipy.spatial.distance import hamming\n",
    "\n",
    "\n",
    "'''\n",
    "Authenticate\n",
    "Authenticates your credentials and creates a client.\n",
    "'''\n",
    "subscription_key = os.environ[\"VISION_KEY\"]\n",
    "endpoint = os.environ[\"VISION_ENDPOINT\"]\n",
    "computervision_client = ComputerVisionClient(endpoint, CognitiveServicesCredentials(subscription_key))\n",
    "'''\n",
    "END - Authenticate\n",
    "'''\n",
    "\n",
    "image = \"poza_eu.jpg\"\n",
    "# img = open(\"test1.png\", \"rb\")\n",
    "# img = open(\"test2.jpeg\", \"rb\")\n",
    "img = open(image, \"rb\")\n",
    "read_response = computervision_client.read_in_stream(\n",
    "    image=img,\n",
    "    mode=\"Printed\",\n",
    "    raw=True\n",
    ")\n",
    "# print(read_response.as_dict())\n",
    "\n",
    "operation_id = read_response.headers['Operation-Location'].split('/')[-1]\n",
    "while True:\n",
    "    read_result = computervision_client.get_read_result(operation_id)\n",
    "    if read_result.status not in ['notStarted', 'running']:\n",
    "        break\n",
    "    time.sleep(1)\n",
    "\n",
    "# Print the detected text, line by line\n",
    "result = []\n",
    "boxes = []\n",
    "if read_result.status == OperationStatusCodes.succeeded:\n",
    "    for text_result in read_result.analyze_result.read_results:\n",
    "        for line in text_result.lines:\n",
    "            print(line.text)\n",
    "            result.append(line.text)\n",
    "            boxes.append(line.bounding_box)\n",
    "\n",
    "print()\n",
    "\n",
    "# get/define the ground truth\n",
    "# groundTruth = [\"Google Cloud\", \"Platform\"]\n",
    "# groundTruth = [\"Succes in rezolvarea\", \"tEMELOR la\", \"LABORAtoaree de\", \"Inteligenta Artificiala!\"]\n",
    "groundTruth = [\"ÃŽn NeamÈ› a nins\", \"ÃŽn Cluj e frig!\"]\n",
    "\n",
    "# compute the performance\n",
    "noOfCorrectLines = sum(i == j for i, j in zip(result, groundTruth))\n",
    "print(noOfCorrectLines)"
   ],
   "id": "949445ed6d5737a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Neamt a mins\n",
      "In Elyj e frig !\n",
      "\n",
      "0\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T13:31:16.092734Z",
     "start_time": "2025-03-20T13:31:16.083233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. Hamming\n",
    "\n",
    "def hamming_distance(detected, truth):\n",
    "    detected_list = list(\" \".join(detected))\n",
    "    truth_list = list(\" \".join(truth))\n",
    "\n",
    "    length = max(len(detected_list), len(truth_list))\n",
    "    detected_list.extend(\" \" * (length - len(detected_list)))\n",
    "    truth_list.extend(\" \" * (length - len(truth_list)))\n",
    "\n",
    "    return hamming(detected_list, truth_list) * length\n",
    "\n",
    "if len(result) == len(groundTruth):\n",
    "    print(f\"Hamming Distance: {hamming_distance(result, groundTruth)}\")\n",
    "else:\n",
    "    print(\"Different text lengths !!\")\n"
   ],
   "id": "d8fdcf4ca3c1583d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming Distance: 8.0\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T13:31:19.793198Z",
     "start_time": "2025-03-20T13:31:19.780870Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 2. Jacard\n",
    "\n",
    "def jaccard_similarity(detected, truth):\n",
    "    detected_set = set(\" \".join(detected).split())\n",
    "    truth_set = set(\" \".join(truth).split())\n",
    "    C = detected_set.intersection(truth_set)\n",
    "    D = detected_set.union(truth_set)\n",
    "    return len(C)/len(D)\n",
    "\n",
    "print(f\"Jaccard Similarity: {jaccard_similarity(result, groundTruth):.2f}\")\n"
   ],
   "id": "b92d7de3c3ccce2f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard Similarity: 0.15\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T16:05:34.274606Z",
     "start_time": "2025-03-20T16:05:34.270326Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 3. Levenshtein\n",
    "\n",
    "def levenshtein_accuracy(detected, truth):\n",
    "    detected_words = [word for line in detected for word in line.split()]\n",
    "    truth_words = [word for line in truth for word in line.split()]\n",
    "\n",
    "    length = max(len(detected_words), len(truth_words))\n",
    "    detected_words.extend(\" \" * (length - len(detected_words)))\n",
    "    truth_words.extend(\" \" * (length - len(truth_words)))\n",
    "\n",
    "    total_chars = sum(len(word) for word in truth_words)\n",
    "    total_words = len(truth_words)\n",
    "\n",
    "    char_errors = sum(Levenshtein.distance(d, t) for d, t in zip(detected_words, truth_words))\n",
    "\n",
    "    return  (1 - char_errors / total_chars) * 100 if total_chars > 0 else 0\n",
    "\n",
    "print(f\"Character accuracy (Levenshtein): {levenshtein_accuracy(result, groundTruth):.2f}%\")\n",
    "\n"
   ],
   "id": "99c9f09617b9f2ce",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character accuracy (Levenshtein): 68.00%\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T13:38:08.512708Z",
     "start_time": "2025-03-20T13:38:08.499907Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Text position\n",
    "\n",
    "def text_position(bounding_box, img_width, img_height):\n",
    "\n",
    "    center_x = (bounding_box[0] + bounding_box[2] + bounding_box[4] + bounding_box[6]) / 4\n",
    "    center_y = (bounding_box[1] + bounding_box[3] + bounding_box[5] + bounding_box[7]) / 4\n",
    "\n",
    "\n",
    "    if center_y < img_height / 3:\n",
    "        vertical = \"Top\"\n",
    "    elif center_y < 2 * img_height / 3:\n",
    "        vertical = \"Middle\"\n",
    "    else:\n",
    "        vertical = \"Bottom\"\n",
    "\n",
    "    if center_x < img_width / 3:\n",
    "        horizontal = \"Left\"\n",
    "    elif center_x < 2 * img_width / 3:\n",
    "        horizontal = \"Center\"\n",
    "    else:\n",
    "        horizontal = \"Right\"\n",
    "\n",
    "    return f\"{vertical}-{horizontal}\"\n",
    "\n",
    "\n",
    "with Image.open(image) as img:\n",
    "    img_width, img_height = img.size\n",
    "\n",
    "\n",
    "for line, box in zip(result, boxes):\n",
    "    region = text_position(box, img_width, img_height)\n",
    "    print(f\"'{line}' : {region} \")\n",
    "\n",
    "contor = 0\n",
    "verify = 0\n",
    "test = [\"Top-Left\", \"Middle-Center\"]\n",
    "for line, box in zip(result, boxes):\n",
    "    region = text_position(box, img_width, img_height)\n",
    "    if region == test[contor]:\n",
    "        verify += 1\n",
    "    contor += 1\n",
    "print(f\" Text position accuracy: {verify/contor * 100} %\")\n",
    "\n",
    "\n"
   ],
   "id": "10d7d159618f060f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In Neamt a mins' : Top-Left \n",
      "'In Elyj e frig !' : Middle-Center \n",
      " Text position accuracy: 100.0 %\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Posibilitati de imbunatatire a recunoasterii textului:\n",
    "\n",
    "# - sa prelucram imaginea pentru a mari distanta intre litere ( a confundat uj cu y)\n",
    "# - sa antrenam modelul pe mai multe exemple de scris de mana (a confundat n -ul cu m pentru ca e scris diferit fata de 'standard'\n",
    "# - prelucrare imagine la nivel de luminozitate, claritate"
   ],
   "id": "816bee047c18e350"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
