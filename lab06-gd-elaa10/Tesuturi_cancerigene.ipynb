{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Clasificarea È›esuturilor cancerigene\n",
    "\n",
    "Se considerÄƒ informaÈ›ii despre cancerul de sÃ¢n la femei, informaÈ›ii extrase din ecografii mamare (detalii aici) precum: - Tipul malformaÈ›iei identificate (È›esut benign sau È›esut malign) - Caracteristici numerice ale nucleului celulelor din aceste È›esuturi: - raza (media distanÈ›elor Ã®ntre centru si punctele de pe contur) - textura (mÄƒsuratÄƒ prin deviaÈ›ia standard a nivelelor de gri din imaginea asociatÄƒ È›esutului analizat) Folosindu-se aceste date, sÄƒ se decidÄƒ dacÄƒ È›esutul dintr-o nouÄƒ ecografie (pentru care se cunosc cele 2 caracteristici numerice â€“ raza È™i textura â€“) va fi etichetat ca fiind malign sau benign.\n",
    "\n",
    "\n",
    "SpecificaÅ£i, proiectaÅ£i, implementaÅ£i si testati cate un algoritm de clasificare pentru problema 2 si problema 3 bazat pe regresie logistica. Antrenati cate un clasificator pentru fiecare problema, pe care apoi sa ii utilizati pentru a stabili:\n",
    "\n",
    "- daca o leziune (dintr-o mamografie) caracterizata printr-o textura de valoare 10 si o raza de valoare 18 este leziune maligna sau benigna\n",
    "\n",
    "\n",
    "ðŸµï¸ Cerinte opÈ›ionale\n",
    "\n",
    "Rezolvarea unei probleme de regresie/clasificare prin:\n",
    "\n",
    "- folosirea validarii Ã®ncruciÈ™ate\n",
    "- investigarea diferitelor funcÈ›ii de loss\n",
    "ce se Ã®ntÃ®mplÄƒ Ã®n cazul clasificarii binare daca se modificÄƒ pragul de decizie din 0.5 Ã®n alte valori. Cum se poate aprecia calitatea clasificatorului pentru diferite valori ale pragului?"
   ],
   "id": "7d54c19c7c29b052"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T16:22:46.730720Z",
     "start_time": "2025-04-17T16:22:46.699089Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "column_names = [\n",
    "    'id', 'diagnosis',\n",
    "    'mean_radius', 'mean_texture', 'mean_perimeter', 'mean_area', 'mean_smoothness',\n",
    "    'mean_compactness', 'mean_concavity', 'mean_concave_points', 'mean_symmetry', 'mean_fractal_dimension',\n",
    "    'se_radius', 'se_texture', 'se_perimeter', 'se_area', 'se_smoothness',\n",
    "    'se_compactness', 'se_concavity', 'se_concave_points', 'se_symmetry', 'se_fractal_dimension',\n",
    "    'worst_radius', 'worst_texture', 'worst_perimeter', 'worst_area', 'worst_smoothness',\n",
    "    'worst_compactness', 'worst_concavity', 'worst_concave_points', 'worst_symmetry', 'worst_fractal_dimension'\n",
    "]\n",
    "\n",
    "data = pd.read_csv(\"data/breast_cancer_wisconsin.csv\", header=None, names=column_names)\n",
    "\n",
    "data.to_csv(\"breast_cancer_wisconsin.csv\", index=False)"
   ],
   "id": "655da9fa957d4437",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T16:22:51.924544Z",
     "start_time": "2025-04-17T16:22:51.355659Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n"
   ],
   "id": "d12b2097a6d3626b",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T16:22:52.953948Z",
     "start_time": "2025-04-17T16:22:52.916464Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "url = \"data/wdbc.data\"\n",
    "column_names = ['id', 'diagnosis', 'radius', 'texture'] + [f'feature_{i}' for i in range(28)]\n",
    "data = pd.read_csv(url, header=None, names=column_names)\n",
    "\n",
    "feature1 = 'radius'\n",
    "feature2 = 'texture'\n",
    "inputs = data[[feature1, feature2]].values\n",
    "outputs = data['diagnosis'].map({'M': 1, 'B': 0}).values\n",
    "\n",
    "trainInputs, testInputs, trainOutputs, testOutputs = train_test_split(inputs, outputs, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "trainInputs = scaler.fit_transform(trainInputs)\n",
    "testInputs = scaler.transform(testInputs)"
   ],
   "id": "dc0336f25ce0f4a0",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T16:22:54.331999Z",
     "start_time": "2025-04-17T16:22:54.295559Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def logistic_regression_tool():\n",
    "\n",
    "    model = LogisticRegression()\n",
    "    model.fit(trainInputs, trainOutputs)\n",
    "\n",
    "    w0 = model.intercept_[0]\n",
    "    w1, w2 = model.coef_[0]\n",
    "    print(f'Model: P(Malign) = 1 / (1 + exp(-({w0:.4f} + {w1:.4f}*x1 + {w2:.4f}*x2)))')\n",
    "\n",
    "    trainPred = model.predict(trainInputs)\n",
    "    testPred = model.predict(testInputs)\n",
    "    print(f'Accuracy - Train: {accuracy_score(trainOutputs, trainPred):.4f}')\n",
    "    print(f'Accuracy - Test: {accuracy_score(testOutputs, testPred):.4f}')\n",
    "\n",
    "    # Predictie pentru (18, 10)\n",
    "    new_sample = scaler.transform([[18, 10]])\n",
    "    prob = model.predict_proba(new_sample)[0][1]\n",
    "    print(f'Probabilitate malign pentru (18,10): {prob:.4f} => {\"Malign\" if prob > 0.5 else \"Benign\"}')\n",
    "\n",
    "\n",
    "logistic_regression_tool()"
   ],
   "id": "81f4f0b4a1230c55",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: P(Malign) = 1 / (1 + exp(-(-0.7168 + 3.1051*x1 + 0.8916*x2)))\n",
      "Accuracy - Train: 0.8879\n",
      "Accuracy - Test: 0.9035\n",
      "Probabilitate malign pentru (18,10): 0.6845 => Malign\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T16:22:56.853088Z",
     "start_time": "2025-04-17T16:22:56.840738Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MyLogisticRegression:\n",
    "    def __init__(self, learning_rate=0.01, n_iters=1000):\n",
    "        self.lr = learning_rate\n",
    "        self.n_iters = n_iters\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "\n",
    "        for _ in range(self.n_iters):\n",
    "            linear = np.dot(X, self.weights) + self.bias\n",
    "            predictions = self._sigmoid(linear)\n",
    "\n",
    "            dw = (1 / n_samples) * np.dot(X.T, (predictions - y))\n",
    "            db = (1 / n_samples) * np.sum(predictions - y)\n",
    "\n",
    "            self.weights -= self.lr * dw\n",
    "            self.bias -= self.lr * db\n",
    "\n",
    "    def predict(self, X):\n",
    "        linear = np.dot(X, self.weights) + self.bias\n",
    "        y_pred = self._sigmoid(linear)\n",
    "        return (y_pred > 0.5).astype(int)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        linear = np.dot(X, self.weights) + self.bias\n",
    "        return self._sigmoid(linear)\n",
    "\n",
    "    def _sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def compute_loss(self, X, y_true):\n",
    "        y_pred = self.predict_proba(X)\n",
    "        # Binary Cross-Entropy Loss\n",
    "        loss = -np.mean(y_true * np.log(y_pred + 1e-15) + (1-y_true) * np.log(1-y_pred + 1e-15))\n",
    "        return loss\n"
   ],
   "id": "3e63116680f769a4",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T16:22:58.818641Z",
     "start_time": "2025-04-17T16:22:58.783112Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def logistic_regression_me():\n",
    "    model = MyLogisticRegression(learning_rate=0.1, n_iters=1000)\n",
    "    model.fit(trainInputs, trainOutputs)\n",
    "\n",
    "    trainPred = model.predict(trainInputs)\n",
    "    testPred = model.predict(testInputs)\n",
    "    print(f'Accuracy - Train: {accuracy_score(trainOutputs, trainPred):.4f}')\n",
    "    print(f'Accuracy - Test: {accuracy_score(testOutputs, testPred):.4f}')\n",
    "\n",
    "    # Predictie pentru (18, 10)\n",
    "    new_sample = scaler.transform([[18, 10]])\n",
    "    prob = model.predict_proba(new_sample)\n",
    "    print(f'Probabilitate malign pentru (18,10): {prob[0]:.4f} => {\"Malign\" if prob > 0.5 else \"Benign\"}')\n",
    "\n",
    "\n",
    "logistic_regression_me()"
   ],
   "id": "59b963ca18f8750a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy - Train: 0.8901\n",
      "Accuracy - Test: 0.9035\n",
      "Probabilitate malign pentru (18,10): 0.6957 => Malign\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "ðŸµï¸ Cerinte opÈ›ionale\n",
    "\n",
    "Rezolvarea unei probleme de regresie/clasificare prin:\n",
    "\n",
    "- folosirea validarii Ã®ncruciÈ™ate"
   ],
   "id": "2bc5fd7dd8fc1206"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T16:23:01.206951Z",
     "start_time": "2025-04-17T16:23:01.163998Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_scores = cross_val_score(LogisticRegression(), inputs, outputs, cv=5, scoring='accuracy')\n",
    "print(f\"Acuratete medie CV (sklearn): {np.mean(cv_scores):.2f} Â± {np.std(cv_scores):.2f}\")"
   ],
   "id": "83112140ab6b2080",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuratete medie CV (sklearn): 0.89 Â± 0.03\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- investigarea diferitelor funcÈ›ii de loss",
   "id": "97fd80eaea21f90"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T16:23:02.900240Z",
     "start_time": "2025-04-17T16:23:02.864905Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = MyLogisticRegression()\n",
    "model.fit(trainInputs, trainOutputs)\n",
    "print(f\"Loss pe setul de antrenare: {model.compute_loss(trainInputs, trainOutputs):.4f}\")"
   ],
   "id": "173a0e422b334743",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss pe setul de antrenare: 0.3268\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Ce se Ã®ntÃ®mplÄƒ Ã®n cazul clasificarii binare daca se modificÄƒ pragul de decizie din 0.5 Ã®n alte valori. Cum se poate aprecia calitatea clasificatorului pentru diferite valori ale pragului?",
   "id": "47b1663f6bc525d2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T16:23:04.988292Z",
     "start_time": "2025-04-17T16:23:04.957319Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_thresholds(model, X, y_true, thresholds=np.linspace(0.1, 0.9, 9)):\n",
    "    y_proba = model.predict_proba(X)\n",
    "    results = []\n",
    "\n",
    "    for thresh in thresholds:\n",
    "        y_pred = (y_proba > thresh).astype(int)\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        results.append((thresh, acc))\n",
    "\n",
    "    return pd.DataFrame(results, columns=['Threshold', 'Accuracy'])\n",
    "\n",
    "\n",
    "model = MyLogisticRegression(learning_rate=0.1, n_iters=1000)\n",
    "model.fit(trainInputs, trainOutputs)\n",
    "threshold_results = evaluate_thresholds(model, testInputs, testOutputs)\n",
    "print(threshold_results)"
   ],
   "id": "fa8ad3573b9be652",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Threshold  Accuracy\n",
      "0        0.1  0.771930\n",
      "1        0.2  0.868421\n",
      "2        0.3  0.894737\n",
      "3        0.4  0.912281\n",
      "4        0.5  0.903509\n",
      "5        0.6  0.903509\n",
      "6        0.7  0.894737\n",
      "7        0.8  0.894737\n",
      "8        0.9  0.815789\n"
     ]
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
